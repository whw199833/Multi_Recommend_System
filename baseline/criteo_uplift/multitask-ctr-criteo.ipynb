{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-11T02:52:11.965863Z",
     "iopub.status.busy": "2022-10-11T02:52:11.965354Z",
     "iopub.status.idle": "2022-10-11T02:52:13.846202Z",
     "shell.execute_reply": "2022-10-11T02:52:13.845407Z",
     "shell.execute_reply.started": "2022-10-11T02:52:11.965832Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-10-11T02:52:13.848648Z",
     "iopub.status.busy": "2022-10-11T02:52:13.847924Z",
     "iopub.status.idle": "2022-10-11T02:53:18.520742Z",
     "shell.execute_reply": "2022-10-11T02:53:18.519796Z",
     "shell.execute_reply.started": "2022-10-11T02:52:13.848611Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/criteo-uplift-v2.1/criteo-uplift-v2.1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTR modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:30:35.142135Z",
     "iopub.status.busy": "2022-10-11T11:30:35.141703Z",
     "iopub.status.idle": "2022-10-11T11:30:45.635689Z",
     "shell.execute_reply": "2022-10-11T11:30:45.634479Z",
     "shell.execute_reply.started": "2022-10-11T11:30:35.142091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
      "\u001b[K     |████████████████████████████████| 529 kB 781 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (20.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.18.5)\n",
      "Requirement already satisfied: torch>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.7.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (3.7.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torchmetrics) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (0.18.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (3.7.4.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (0.6)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.18.5)\n",
      "Installing collected packages: torchmetrics\n",
      "Successfully installed torchmetrics-0.10.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install deepctr_torch\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modeling defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:30:45.638461Z",
     "iopub.status.busy": "2022-10-11T11:30:45.638108Z",
     "iopub.status.idle": "2022-10-11T11:30:56.766953Z",
     "shell.execute_reply": "2022-10-11T11:30:56.765621Z",
     "shell.execute_reply.started": "2022-10-11T11:30:45.638427Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import auc\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from torchmetrics.classification import BinaryPrecision\n",
    "from torchmetrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:32:14.765713Z",
     "iopub.status.busy": "2022-10-11T11:32:14.765181Z",
     "iopub.status.idle": "2022-10-11T11:32:14.777113Z",
     "shell.execute_reply": "2022-10-11T11:32:14.775822Z",
     "shell.execute_reply.started": "2022-10-11T11:32:14.765655Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleCustomBatch:\n",
    "    def __init__(self, data):\n",
    "        transposed_data = list(zip(*data))\n",
    "        self.inp = torch.stack(transposed_data[0], 0)\n",
    "        self.tgt = torch.stack(transposed_data[1], 0)\n",
    "\n",
    "    # custom memory pinning method on custom type\n",
    "    def pin_memory(self):\n",
    "        self.inp = self.inp.pin_memory()\n",
    "        self.tgt = self.tgt.pin_memory()\n",
    "        return self\n",
    "\n",
    "def collate_wrapper(batch):\n",
    "    return SimpleCustomBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:32:14.780708Z",
     "iopub.status.busy": "2022-10-11T11:32:14.780223Z",
     "iopub.status.idle": "2022-10-11T11:32:22.973135Z",
     "shell.execute_reply": "2022-10-11T11:32:22.971765Z",
     "shell.execute_reply.started": "2022-10-11T11:32:14.780662Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'treatment']]\n",
    "Y = df[['conversion', 'visit', 'exposure']]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:32:26.975160Z",
     "iopub.status.busy": "2022-10-11T11:32:26.974625Z",
     "iopub.status.idle": "2022-10-11T11:32:28.025565Z",
     "shell.execute_reply": "2022-10-11T11:32:28.024258Z",
     "shell.execute_reply.started": "2022-10-11T11:32:26.975115Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat([X, Y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:33:34.261613Z",
     "iopub.status.busy": "2022-10-11T11:33:34.260863Z",
     "iopub.status.idle": "2022-10-11T11:33:34.267314Z",
     "shell.execute_reply": "2022-10-11T11:33:34.266602Z",
     "shell.execute_reply.started": "2022-10-11T11:33:34.261568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       'f11', 'treatment', 'conversion', 'visit', 'exposure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:41:13.775613Z",
     "iopub.status.busy": "2022-10-11T11:41:13.774914Z",
     "iopub.status.idle": "2022-10-11T11:41:13.944675Z",
     "shell.execute_reply": "2022-10-11T11:41:13.943749Z",
     "shell.execute_reply.started": "2022-10-11T11:41:13.775552Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['type'] = train_data['conversion'] + train_data['visit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:53:03.038356Z",
     "iopub.status.busy": "2022-10-11T11:53:03.037828Z",
     "iopub.status.idle": "2022-10-11T11:53:06.793225Z",
     "shell.execute_reply": "2022-10-11T11:53:06.791967Z",
     "shell.execute_reply.started": "2022-10-11T11:53:03.038289Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data0 = train_data[train_data['type']==0].sample(frac = 0.05)\n",
    "train_data1 = train_data[train_data['type']==1].sample(frac = 1)\n",
    "train_data2 = train_data[train_data['type']==2].sample(frac = 1)\n",
    "\n",
    "train_data = pd.concat([train_data0, train_data1, train_data2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:54:16.577387Z",
     "iopub.status.busy": "2022-10-11T11:54:16.576962Z",
     "iopub.status.idle": "2022-10-11T11:54:16.789291Z",
     "shell.execute_reply": "2022-10-11T11:54:16.788127Z",
     "shell.execute_reply.started": "2022-10-11T11:54:16.577350Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_data[['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'treatment']], train_data[['conversion', 'visit', 'exposure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:54:19.552272Z",
     "iopub.status.busy": "2022-10-11T11:54:19.551705Z",
     "iopub.status.idle": "2022-10-11T11:54:20.378218Z",
     "shell.execute_reply": "2022-10-11T11:54:20.376971Z",
     "shell.execute_reply.started": "2022-10-11T11:54:19.552238Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = torch.tensor(np.array(train_x)).to(torch.float), torch.tensor(np.array(test_x)).to(torch.float), torch.tensor(np.array(train_y)).to(torch.float), torch.tensor(np.array(test_y)).to(torch.float)\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:58:49.963874Z",
     "iopub.status.busy": "2022-10-11T11:58:49.963381Z",
     "iopub.status.idle": "2022-10-11T11:58:49.975086Z",
     "shell.execute_reply": "2022-10-11T11:58:49.974100Z",
     "shell.execute_reply.started": "2022-10-11T11:58:49.963821Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output1_size, output2_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.fc_mid = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size+output2_size, output1_size)\n",
    "#         self.fc2 = nn.Linear(output2_size, output1_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output2_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.leakyrelu(self.fc1(x))\n",
    "        out = self.leakyrelu(self.fc_mid(out))\n",
    "        out2 = self.fc3(out)\n",
    "        out1 = self.fc2(self.leakyrelu(torch.cat((out, out2), 1)))\n",
    "#         out1 = self.fc2(out2)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T11:58:49.977286Z",
     "iopub.status.busy": "2022-10-11T11:58:49.976821Z",
     "iopub.status.idle": "2022-10-11T11:58:49.989881Z",
     "shell.execute_reply": "2022-10-11T11:58:49.988901Z",
     "shell.execute_reply.started": "2022-10-11T11:58:49.977224Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net(train_x.shape[1], 2*train_x.shape[1], 2, 2)\n",
    "loss_fct = CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-4)\n",
    "\n",
    "log_interval = 1000\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T12:02:49.284735Z",
     "iopub.status.busy": "2022-10-11T12:02:49.284256Z",
     "iopub.status.idle": "2022-10-11T12:05:53.946420Z",
     "shell.execute_reply": "2022-10-11T12:05:53.944634Z",
     "shell.execute_reply.started": "2022-10-11T12:02:49.284697Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1 on batch 0:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 0:  0.96875, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.48438\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.00195, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.00098\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.17188, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.08594\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.35742, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.17871\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.36328, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.18164\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.46289, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.23145\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.00000\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.00000\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.00000\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 0:  0.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.00000\n",
      "Accuracy2 on batch 0:  0.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 0.00000\n",
      " \n",
      "Accuracy1 on batch 1000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 1000:  1.00000, auc2: 0.00000, F1_2: 0.00000, precision2: 0.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy1 on batch 2000:  1.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 1.00000\n",
      "Accuracy2 on batch 2000:  1.00000, auc2: 0.00000, F1_2: 1.00000, precision2: 1.00000, recall2: 1.00000\n",
      " \n",
      "Accuracy on all data: 0.7221028804779053\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "metric = torchmetrics.Accuracy()\n",
    "F1 = BinaryF1Score()\n",
    "Precision = BinaryPrecision()\n",
    "recall = Recall(average='macro', num_classes=2)\n",
    "for _ in range(epochs):\n",
    "    for batch_ndx, sample in enumerate(train_loader):\n",
    "        pred_1, pred_2 = model(sample[0])\n",
    "\n",
    "\n",
    "        loss1 = loss_fct(pred_1, sample[1][:,0].to(torch.long))\n",
    "        loss2 = loss_fct(pred_2, sample[1][:,1].to(torch.long))\n",
    "\n",
    "\n",
    "        loss = loss1 + loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_ndx % log_interval == 0:\n",
    "            loss = loss.item()\n",
    "    #         logger.info(f\"eval loss: {loss:>7f}   eval accuracy: {accuracy:>7f}  curent step: [{current_step}]\")\n",
    "\n",
    "            acc1 = metric(pred_1, sample[1][:,0].to(torch.long))\n",
    "            acc2 = metric(pred_2, sample[1][:,1].to(torch.long))\n",
    "\n",
    "            prediction1 = torch.max(F.softmax(pred_1),1)[1]\n",
    "            prediction2 = torch.max(F.softmax(pred_2),1)[1]  \n",
    "\n",
    "            auc1 = auc(prediction1, sample[1][:,0], reorder=True)\n",
    "            auc2 = auc(prediction2, sample[1][:,1], reorder=True)\n",
    "\n",
    "            F1_1 = F1(prediction1, sample[1][:,0])\n",
    "            F1_2 = F1(prediction2, sample[1][:,1])\n",
    "\n",
    "            Precision1 = Precision(prediction1, sample[1][:,0])\n",
    "            Precision2 = Precision(prediction2, sample[1][:,1])\n",
    "\n",
    "            recall1 = recall(prediction1, sample[1][:,0].to(torch.int))\n",
    "            recall2 = recall(prediction2, sample[1][:,1].to(torch.int))\n",
    "\n",
    "            print(f\"Accuracy1 on batch {batch_ndx}: {acc1: .5f}, auc1:{auc1: .5f}, F1_1:{F1_1: .5f}, precision1:{Precision1: .5f}, recall1:{recall1: .5f}\")\n",
    "            print(f\"Accuracy2 on batch {batch_ndx}: {acc2: .5f}, auc2:{auc2: .5f}, F1_2:{F1_2: .5f}, precision2:{Precision2: .5f}, recall2:{recall2: .5f}\")\n",
    "            print(' ')\n",
    "\n",
    "    #     break\n",
    "    \n",
    "    \n",
    "# metric on all batches using custom accumulation\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data: {acc}\")\n",
    "\n",
    "metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T12:24:38.624545Z",
     "iopub.status.busy": "2022-10-11T12:24:38.623974Z",
     "iopub.status.idle": "2022-10-11T12:24:53.165037Z",
     "shell.execute_reply": "2022-10-11T12:24:53.164063Z",
     "shell.execute_reply.started": "2022-10-11T12:24:38.624492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1 on batch 0:  0.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.00000\n",
      "Accuracy2 on batch 0:  0.04883, auc2: 0.00000, F1_2: 0.09311, precision2: 0.04883, recall2: 0.50000\n",
      " \n",
      "Accuracy1 on batch 1000:  0.00391, auc1: 0.00000, F1_1: 0.00778, precision1: 0.00391, recall1: 0.50000\n",
      "Accuracy2 on batch 1000:  0.04883, auc2: 0.00000, F1_2: 0.09311, precision2: 0.04883, recall2: 0.50000\n",
      " \n",
      "Accuracy1 on batch 2000:  0.00000, auc1: 0.00000, F1_1: 0.00000, precision1: 0.00000, recall1: 0.00000\n",
      "Accuracy2 on batch 2000:  0.04297, auc2: 0.00000, F1_2: 0.08240, precision2: 0.04297, recall2: 0.50000\n",
      " \n",
      "Accuracy on all data: 0.02408854104578495\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "metric = torchmetrics.Accuracy()\n",
    "F1 = BinaryF1Score()\n",
    "Precision = BinaryPrecision()\n",
    "recall = Recall(average='macro', num_classes=2)\n",
    "\n",
    "for batch_ndx, sample in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        pred_1, pred_2 = model(sample[0])\n",
    "        loss1 = loss_fct(pred_1, sample[1][:,0].to(torch.long))\n",
    "        loss2 = loss_fct(pred_2, sample[1][:,1].to(torch.long))\n",
    "        \n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        if batch_ndx % log_interval == 0:\n",
    "\n",
    "            acc1 = metric(pred_1, sample[1][:,0].to(torch.long))\n",
    "            acc2 = metric(pred_2, sample[1][:,1].to(torch.long))\n",
    "\n",
    "            prediction1 = torch.max(F.softmax(pred_1),1)[1]\n",
    "            prediction2 = torch.max(F.softmax(pred_2),1)[1]  \n",
    "\n",
    "            auc1 = auc(prediction1, sample[1][:,0], reorder=True)\n",
    "            auc2 = auc(prediction2, sample[1][:,1], reorder=True)\n",
    "\n",
    "            F1_1 = F1(prediction1, sample[1][:,0])\n",
    "            F1_2 = F1(prediction2, sample[1][:,1])\n",
    "\n",
    "            Precision1 = Precision(prediction1, sample[1][:,0])\n",
    "            Precision2 = Precision(prediction2, sample[1][:,1])\n",
    "\n",
    "            recall1 = recall(prediction1, sample[1][:,0].to(torch.int))\n",
    "            recall2 = recall(prediction2, sample[1][:,1].to(torch.int))\n",
    "\n",
    "            print(f\"Accuracy1 on batch {batch_ndx}: {acc1: .5f}, auc1:{auc1: .5f}, F1_1:{F1_1: .5f}, precision1:{Precision1: .5f}, recall1:{recall1: .5f}\")\n",
    "            print(f\"Accuracy2 on batch {batch_ndx}: {acc2: .5f}, auc2:{auc2: .5f}, F1_2:{F1_2: .5f}, precision2:{Precision2: .5f}, recall2:{recall2: .5f}\")\n",
    "            print(' ')\n",
    "            \n",
    "# metric on all batches using custom accumulation\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data: {acc}\")\n",
    "\n",
    "metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
